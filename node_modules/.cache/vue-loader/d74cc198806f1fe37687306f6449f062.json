{"remainingRequest":"/Users/gustavoreis/faceRecognition-Vuejs/node_modules/vue-loader/lib/index.js??vue-loader-options!/Users/gustavoreis/faceRecognition-Vuejs/src/components/Main.vue?vue&type=style&index=0&id=54d3a52e&scoped=true&lang=css","dependencies":[{"path":"/Users/gustavoreis/faceRecognition-Vuejs/src/components/Main.vue","mtime":1706315704350},{"path":"/Users/gustavoreis/faceRecognition-Vuejs/node_modules/css-loader/dist/cjs.js","mtime":1706315721470},{"path":"/Users/gustavoreis/faceRecognition-Vuejs/node_modules/vue-loader/lib/loaders/stylePostLoader.js","mtime":1706315721833},{"path":"/Users/gustavoreis/faceRecognition-Vuejs/node_modules/postcss-loader/src/index.js","mtime":1706315721560},{"path":"/Users/gustavoreis/faceRecognition-Vuejs/node_modules/cache-loader/dist/cjs.js","mtime":1706315721178},{"path":"/Users/gustavoreis/faceRecognition-Vuejs/node_modules/vue-loader/lib/index.js","mtime":1706315721622}],"contextDependencies":[],"result":[{"type":"Buffer","data":"base64:Ci5pbWdjYW52YXMgewogIHdpZHRoOiA0MDBweDsKICBoZWlnaHQ6IDMwMHB4OwogIGJvcmRlcjogMnB4IHNvbGlkICMwMDA7CiAgbWFyZ2luOiAxMHB4Owp9Cg=="},{"version":3,"sources":["Main.vue"],"names":[],"mappings":";AA6HA;AACA;AACA;AACA;AACA;AACA","file":"Main.vue","sourceRoot":"src/components","sourcesContent":["<template>\n  <div class=\"hello\">\n    <h1>{{ msg }}</h1>\n    <div>\n      <video ref=\"video\" width=\"400\" height=\"300\" autoplay></video>\n      <button @click=\"startCamera\">Start Camera</button>\n      <button @click=\"stopCamera\">Stop Camera</button>\n      <p>PEOPLE COUNT: {{ peopleCount }}</p>\n    </div>\n    <!-- Removendo a segunda seção de câmera -->\n    <!-- <div>\n      <canvas id=\"srcimg\" ref=\"srcimg\" class=\"imgcanvas\"></canvas>\n      <canvas id=\"dstimg\" ref=\"dstimg\" class=\"imgcanvas\"></canvas>\n    </div> -->\n    <canvas id=\"canvas\" ref=\"canvas\" class=\"imgcanvas\"></canvas>\n  </div>\n</template>\n\n<script>\nimport axios from 'axios'\n\nexport default {\n  name: 'Main',\n  props: {\n    msg: String\n  },\n  data() {\n    return {\n      faceClass: null,\n      eyeClass: null,\n      files: [],\n      videoStream: null,\n      peopleCount: 0\n    }\n  },\n  created() {\n    let cascadeFile = 'haarcascade_frontalface_default.xml'\n    this.createFileFromURL(cascadeFile, cascadeFile, (face) => { this.faceClass = face })\n    cascadeFile = 'haarcascade_eye.xml'\n    this.createFileFromURL(cascadeFile, cascadeFile, (eye) => { this.eyeClass = eye })\n  },\n  methods: {\n    startCamera() {\n      navigator.mediaDevices.getUserMedia({ video: true })\n        .then(stream => {\n          this.$refs.video.srcObject = stream;\n          this.videoStream = stream;\n          this.$refs.video.play();\n          this.detectFace();\n        })\n        .catch(err => {\n          console.error('Error accessing camera:', err);\n        });\n    },\n    stopCamera() {\n      if (this.videoStream) {\n        this.videoStream.getTracks().forEach(track => {\n          track.stop();\n        });\n      }\n    },\n    detectFace() {\n      let video = this.$refs.video;\n      let canvas = this.$refs.canvas;\n      let ctx = canvas.getContext('2d');\n\n      const drawFrame = () => {\n        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n        let srcMat = this.$cv.imread(canvas);\n        let gray = new this.$cv.Mat();\n        this.$cv.cvtColor(srcMat, gray, this.$cv.COLOR_RGBA2GRAY);\n        let faces = new this.$cv.RectVector();\n        let eyes = new this.$cv.RectVector();\n        this.faceClass.detectMultiScale(gray, faces);\n        this.peopleCount = faces.size();\n        for (let i = 0; i < faces.size(); i++) {\n          let roiGray = gray.roi(faces.get(i));\n          let roiSrc = srcMat.roi(faces.get(i));\n          let point1 = new this.$cv.Point(faces.get(i).x, faces.get(i).y);\n          let point2 = new this.$cv.Point(faces.get(i).x + faces.get(i).width, faces.get(i).y + faces.get(i).height);\n          this.$cv.rectangle(srcMat, point1, point2, [255, 0, 0, 255]);\n          this.eyeClass.detectMultiScale(roiGray, eyes);\n          for (let j = 0; j < eyes.size(); j++) {\n            let point1 = new this.$cv.Point(eyes.get(j).x, eyes.get(j).y);\n            let point2 = new this.$cv.Point(eyes.get(j).x + eyes.get(j).width, eyes.get(j).y + eyes.get(j).height);\n            this.$cv.rectangle(roiSrc, point1, point2, [0, 255, 0, 255]);\n          }\n          roiGray.delete();\n          roiSrc.delete();\n        }\n        this.$cv.imshow(canvas, srcMat);\n        srcMat.delete();\n        gray.delete();\n        faces.delete();\n        eyes.delete();\n        requestAnimationFrame(drawFrame);\n      };\n\n      drawFrame();\n    },\n    createFileFromURL(file, url, cb) {\n      axios.get('/models/haarcascades/' + url)\n        .then((resp) => {\n          let rtn = this.$cv.FS_createDataFile('/', file, resp.data, true, false, false)\n          if (!rtn) return cb(null)\n          let classifier = new this.$cv.CascadeClassifier()\n          rtn = classifier.load(file)\n          if (!rtn) return cb(null)\n\n          cb(classifier)\n          console.log('loaded', rtn, classifier.empty(), this.faceClass)\n\n        })\n        .catch((err) => {\n          console.log('ERR', err);\n        })\n    }\n  },\n  beforeDestroy() {\n    this.stopCamera();\n  }\n}\n</script>\n\n<style scoped>\n.imgcanvas {\n  width: 400px;\n  height: 300px;\n  border: 2px solid #000;\n  margin: 10px;\n}\n</style>\n"]}]}